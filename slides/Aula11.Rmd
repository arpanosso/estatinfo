---
# Para transformar em PDF, usar: 
# pagedown::chrome_print("slides/Aula08.html")
# imagens https://www.pexels.com/pt-br/
# gifs https://giphy.com/
# https://www.ime.usp.br/~rfarias/simbolos.html
title: "Estatística e Informática"
subtitle: "Aula 11 - Estimação e Teste de Hipótese"
author: "Alan Rodrigo Panosso <alan.panosso@unesp.br>"
institute: "Departamento de Engenharia e Ciências Exatas FCAV/UNESP"
date: "(01-07-2021)"
encoding: "UTF-8"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(echo=TRUE, message = FALSE, warning = FALSE, comment = "#>", fig.align = "center")
options(dplyr.print_min = 5, dplyr.print_max = 5)
```

class: middle, center, inverse

# Conceitos Básicos

---

### Parâmetro e Estatística

**Parâmetro**: é uma medida usada para descrever uma característica da população.


**Estatística** ou **Estimador**: é qualquer função de uma amostra aleatória (fórmula ou expressão), construída com o propósito de servir como instrumento para descrever alguma característica da amostra e para fazer *inferência* a respeito da característica na população.  


Resumo | Parâmetro | Estatística
---|:---:|:---:
Média | $\mu$ | $\bar{x}=\frac{1}{n} \sum \limits_{i=1}^n x_i$
Variância | $\sigma^2$| $s^2 = \frac{1}{n-1} \sum \limits_{i=1}^n {(x_i - \mu)^2}$
Proporção | $\pi$ | $\hat{p}= \frac{X}{n}$

O valor numérico da estatística ou estimador de um parâmetro, calculado para uma amostra observada, é chamado de estimativa desse parâmetro.

A diferença entre estatística e estimativa é que a **estatística** é uma variável aleatória, e a estimativa é uma particular valor dessa variável aleatória.


---

## Acurácia  
A acurácia mede quão próximo o valor estimado está do valor real, ou seja, é a habilidade do estimador de estimar o valor real.


## Precisão  
A Precisão mede quão próximas estimativas individuais estão umas das outras, ou seja é a habilidade do estimador de estimar valores similares de maneira consistente.

--

```{r,out.width = "100%",fig.cap="",fig.align = 'center',echo=FALSE}
knitr::include_graphics("https://raw.githubusercontent.com/arpanosso/estatinfo/master/slides/img/acuracia_precisao.png")
```

---

## Propriedades de um bom estimador

**1) Consistência**: é uma propriedade por meio da qual a acurácia de uma estimativa aumenta quando o tamanho da amostra aumenta. Assim dado um parâmetro populacional $\theta$ e $\hat{\theta}$  o estimador desse parâmetro, As condições suficientes para um estimador ser consistente são:

$$\lim_{n \to \infty}E(\hat{\theta}) = \theta$$

$$\lim_{n \to \infty}Var(\hat{\theta}) = 0$$

### Exemplo

$$E(\bar{X}) = \mu \text{ e } Var(\bar{X})= \frac{Var(X)}{n}$$

---

## Propriedades de um bom estimador

**2) Não viciado ou não viesado**: O estimador  $\hat{\theta}$   como uma variável aleatória, tem uma certa distribuição em repetidas amostras de tamanho n. Não viciado é uma propriedade que assegura que, em média, o estimador é correto.:

O **estimador** é chamado **não viciado** ou **imparcial** se seu valor esperado ou médio for igual ao verdadeiro valor do parâmetro, ou seja:

$$E(\hat{\theta}) = \theta$$

Entretanto, se

$E(\hat{\theta}) = \theta + b(\theta)$ com $b(\theta) \neq 0$,

o estimador é **viciado** e a quantidade $b(\theta)$ é chamada vício ou viés.

---
### Exemplos de Estimadores

Estes estimadores nada mais são do que as próprias definições dos respectivos parâmetros, mas aplicadas à amostra:

$E(\bar{X})=\mu$ e $E(\hat{p}) = p$


Por sua vez, para a variância o estimador populacional $\sigma^2 = \frac{1}{n} \sum \limits_{i=1}^n (x -\bar{x})^2$ é viciado, pois, podemos demonstrar que:

$E(\hat{\sigma}^2)=\frac{n-1}{n}\sigma^2 = \sigma^2 - \frac{1}{n}\sigma^2$

onde o viés $b(\sigma^2) = -\frac{1}{n} \sigma^2$.

Abaixo segue o estimador não viciado para variância:

$s^2 = \frac{1}{n-1} \sum \limits_{i=1}^n (x -\bar{x})^2$  

No entanto, para $n \to \infty$, têm-se para ambos os estimadores convergem para $\sigma^2$, ou seja, $\hat{\sigma}^2$ e $s^2$ são assintoticamente não viciados.

---
class: middle, center, inverse

# Estimativa por Ponto e por Intervalo

---

### Estimativa por ponto

É a estimativa de um parâmetro populacional dada por um único valor para a estatística, exemplo:


$$\hat{X} = \mu$$

esse procedimento não permite julgar qual a possível magnitude do erro que se está cometendo.

**Exemplo**: O diâmetro a altura do peito de árvores de Eucalipto tem uma média de $105 \;cm$,

--

### Estimativa por intervalo

É a estimativa de um parâmetro populacional baseada na distribuição amostral do estimador pontual, dada por dois valores $a$ e $b$ $(a < b)$, entre os quais se considera que o parâmetro esteja contido.

Essas estimativas indicam a sua precisão ou acurácia, por isto são preferíveis às estimativas por ponto.

A declaração da precisão de uma estimativa por intervalo denomina-se grau de confiança ou **nível de confiança**, daí a denominação de **Intervalo de Confiança**.

**Exemplo**: O diâmetro a altura do peito de árvores de Eucalipto tem uma média de $105 \pm 0,05\;cm$,

---

class: middle, center, inverse

# Estimativa por Intervalo de Confiança

---

### Estimativa por intervalo de confiança

Um intervalo de confiança para $\theta$ é um intervalo construído a partir das observações da amostra, de modo que ele inclui o verdadeiro e desconhecido valor de $\theta$, **com uma específica e alta probabilidade** denotada por $1 - \alpha$, é tipicamente tomada como:

$$NC = P(a \le \theta \le b) = 1-\alpha$$

Então, o intervalo $] a, b [$ é chamado intervalo com $100 \cdot (1 - \alpha)\%$ de confiança para o parâmetro $\theta$, onde: $1 ‑ \alpha$  é  o **nível de confiança** associado ao intervalo $a$ e $b$ são os **limites de confiança**, inferior e superior, respectivamente, do intervalo.

Onde temos a seguinte relação:

Nível de Confiança (NC) | Nível de significância $(\alpha)$
:---:|:---:
$0,90$ | $0,10$
$0,95$ | $0,05$
$0,99$ | $0,01$


---
class: middle, center, inverse

# Intervalo de Confiança para a Média Populacional $(\mu)$

---

## Precisamos definir 4 casos:

### (a) Caso em que $n$ é grande e $\sigma$ conhecido.

### (b) Caso em que $n$ é grande e $\sigma$ desconhecido.

### (c) Caso em que as amostras são pequenas $(n < 30)$ $\sigma$ conhecido.

### (d) Caso em que as amostras são pequenas $(n < 30)$ e $\sigma$ desconhecido

---

## (a) Caso em que $n$ é grande $(n \ge 30)$ e $\sigma$ conhecido.

O desenvolvimento de intervalos de confiança para $\mu$ é baseado na distribuição amostral de $\bar{X}$ se o tamanho da amostra $(n)$ é grande:

$$Z = \frac{\bar{X}- \mu}{\frac{\sigma}{\sqrt{n}}} \cong N(0,1)$$


```{r,out.width = "100%",fig.cap="",fig.align = 'center',echo=FALSE}
knitr::include_graphics("https://raw.githubusercontent.com/arpanosso/estatinfo/master/slides/img/acuracia_precisao.png")
```
